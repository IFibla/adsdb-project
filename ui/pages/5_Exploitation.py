import streamlit as st
import sys
import os

current_script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_script_dir, "..", ".."))
sys.path.insert(0, project_root)
from src.helpers.db_connector import DBConnector

trusted_db_connector = DBConnector("../data/db_exploitation.duckdb")

st.title("Exploitation")

st.header("Motor Vehicle Collisions Rating By Brand")

st.markdown(
    """
In this step, four datasets related to motor vehicle collisions and vehicle safety ratings are merged to create 
a unified DataFrame for analysis. The datasets are `mvc_crash`, `mvc_person`, `mvc_vehicles`, and `nhtsa_safety_rating`. 
The layer retrieves these datasets as DataFrames and performs inner joins on the `collision_id` column to combine 
`mvc_crash`, `mvc_person`, and `mvc_vehicles` into a single DataFrame.

Next, the layer processes the `nhtsa_safety_rating` DataFrame by converting the `make` column to lowercase for 
consistency and calculating the average `overall_rating` for each vehicle make. It then merges this safety ratings 
DataFrame with the combined collision DataFrame on the vehicle make columns (`"vehicle_make"` and `"make"`). After 
merging, it filters out any rows with missing `overall_rating` values to ensure data integrity. The final DataFrame, 
`mvc_sr_df`, contains detailed collision data linked with average safety ratings of the vehicle brands involved, 
enabling analysis of the relationship between vehicle safety ratings and collision outcomes.
"""
)

st.dataframe(
    trusted_db_connector.get_table_as_dataframe("mvc_safety_rating_by_brand", limit=10)
)
